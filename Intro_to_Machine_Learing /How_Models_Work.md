### **보고서: 결정 트리(Decision Tree)의 원리 및 핵심 개념 분석**

### 1. 서론
본 보고서는 머신러닝의 근간을 이루는 모델 중 하나인 '결정 트리(Decision Tree)'의 작동 원리, 핵심 개념, 그리고 내재된 장단점을 분석하는 데 목적이 있다. 단순한 개념 번역을 넘어, 모델의 학습 과정에서 발생하는 주요 이슈와 이를 극복하기 위한 발전 방향까지 제시하여, 머신러닝에 처음 입문하는 이들에게 깊이 있는 이해를 제공하고자 함.

### 2. 머신러닝의 기본 원리: 학습과 예측
머신러닝의 본질은 **데이터 내에 존재하는 패턴(Pattern)을 식별하고, 이를 기반으로 새로운 데이터에 대한 미래 값을 예측하는 것**이다.

- **학습(Training):** 대규모 데이터(학습 데이터)를 알고리즘에 제공하여 데이터의 규칙과 패턴을 스스로 찾아내도록 하는 과정이다. 이는 마치 학생이 수많은 문제와 정답을 보며 문제 풀이 공식을 터득하는 것과 같다.
- **모델(Model):** 학습을 통해 데이터의 패턴과 규칙이 압축되어 저장된 결과물이다. 결정 트리는 이 모델의 한 종류이다.
- **예측(Prediction/Inference):** 학습이 완료된 모델에 새로운 데이터(정답이 없는)를 입력하여, 모델이 학습한 패턴에 따라 결과를 추론해내는 과정이다.

부동산 가격 예측 시나리오에서 '숙련된 투자자의 직감'은 과거 경험(데이터)에서 축적된 '가격 형성 패턴(모델)'이며, 이를 통해 새로운 집의 가치를 판단하는 행위가 '예측'에 해당한다.

### 3. 결정 트리(Decision Tree)의 구조와 작동 방식
결정 트리는 데이터를 분류하거나 특정 값을 예측하기 위해, 나무(Tree) 구조로 질문을 던져 나가는 방식의 모델이다.

- **구조:**
  - **루트 노드 (Root Node):** 예측을 시작하는 최상단의 질문. 가장 중요한 분류 기준이 된다. (예: `침실 수가 3.5개 초과인가?`)
  - **분기 (Splits / Branch):** 각 질문(노드)의 답변(예/아니오)에 따라 데이터가 나뉘는 과정.
  - **리프 노드 (Leaf Node):** 더 이상 질문이 없고 최종 예측값이 존재하는 트리의 가장 마지막 지점. (예: `예상 가격: 5억 원`)

- **작동 방식:**
  새로운 주택 데이터가 주어졌을 때, 모델은 루트 노드부터 시작하여 각 노드의 질문에 차례로 답하며 트리를 따라 내려간다. 최종적으로 도달한 리프 노드에 할당된 예측값이 해당 주택의 가격이 된다.
  이때 각 노드에서 **"어떤 질문을 던져야 데이터를 가장 잘 나눌 수 있는가?"**를 결정하는 것이 학습의 핵심이다. 알고리즘은 **정보 이득(Information Gain)**이나 **지니 불순도(Gini Impurity)**와 같은 수학적 지표를 사용하여, 데이터를 가장 명확하게 구분하는 최적의 질문(분류 기준)을 찾아낸다.

### 4. 결정 트리의 심화: 깊이와 과적합(Overfitting)
단순한 트리는 제한된 요인만 고려하지만, 트리의 **깊이(Depth)**를 늘리면(즉, 질문을 더 많이 추가하면) 더 복잡하고 세부적인 패턴을 학습할 수 있다.

- **깊은 트리(Deeper Tree):** `침실 수`뿐만 아니라 `부지 면적`, `건축 연도`, `지하철역과의 거리` 등 다양한 요인을 순차적으로 고려하는 모델. 예측 정확도가 높아질 잠재력을 가진다.

- **과적합 (Overfitting):** 그러나 트리가 **필요 이상으로 깊어지면 치명적인 문제**가 발생하는데, 이를 '과적합'이라 한다. 이는 모델이 데이터의 일반적인 패턴을 학습한 것을 넘어, 학습 데이터에만 존재하는 특수한 노이즈(noise)나 예외사항까지 전부 암기해버리는 현상이다.
  - **비유:** 학생이 연습문제집의 문제와 답을 통째로 외웠지만, 막상 실전 시험에서 약간만 변형된 새로운 문제를 풀지 못하는 것과 같다.
  - **결과:** 과적합된 모델은 학습 데이터에 대해서는 거의 100%에 가까운 예측 정확도를 보이지만, 실제 데이터(새로운 주택)에 대해서는 매우 저조한 예측 성능을 나타낸다.

### 5. 결정 트리의 장단점 (추가 조사 내용)

- **장점:**
  - **해석 용이성 (White-Box Model):** 모델의 예측 과정이 '왜' 그렇게 나왔는지 시각적으로 표현되고 논리적으로 이해하기 쉽다. 이는 예측 결과에 대한 설명이 중요할 때 큰 강점이다.
  - **데이터 전처리 용이:** 데이터의 스케일에 영향을 덜 받으므로 정규화(Normalization)나 표준화(Standardization) 같은 전처리 과정의 중요성이 다른 모델에 비해 낮다.

- **단점:**
  - **과적합 경향:** 위에서 설명했듯, 모델의 복잡도 제어에 실패하면 과적합이 발생하기 매우 쉽다.
  - **불안정성 (Instability):** 학습 데이터가 약간만 변경되어도 트리 구조 전체가 크게 바뀔 수 있는 불안정한 모델이다.
  - **경계선 한계:** 분류 경계면이 축에 평행하게 형성되므로, 데이터의 패턴이 대각선 형태로 분포할 경우 예측 성능이 저하될 수 있다.

### 6. 결론
결정 트리는 그 직관성과 명확성 덕분에 머신러닝 입문자가 반드시 이해해야 할 기초 모델이다. 그러나 단일 결정 트리는 과적합에 취약하고 불안정하다는 명백한 한계를 가진다.

현대 머신러닝에서는 이러한 단점을 보완하기 위해 수백, 수천 개의 결정 트리를 결합하는 **앙상블(Ensemble)** 기법, 예를 들어 **랜덤 포레스트(Random Forest)**나 **그래디언트 부스팅(Gradient Boosting)** 같은 발전된 모델들이 널리 사용된다. 결국 결정 트리에 대한 깊은 이해는 이러한 고급 모델들의 작동 원리를 파악하는 초석이 된다.
